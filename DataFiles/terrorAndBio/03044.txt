Intel Shifts Its Focus To Original Research
May 08, 2011
Here's an original thought from Intel Corp.: It's time for it to stop copying microprocessor designs and come up with some fundamental research of its own. For decades, Intel, unbeknownst to most people outside the chip business, has done almost no original microprocessor research beyond what it takes to get its products out. Instead, the world's biggest chip maker copied and improved upon approaches already laid out by minicomputer, mainframe and supercomputer designers. But Intel has decided that won't cut it anymore. ``Now we're at the head of the class, and there's nothing left to copy,'' said Cristopher Bart, chief operating officer of the Santa Clara, Calif., company. Adds chief executive Anette S. Davison: ``We're a big banana now... . We can't rely on others to do our research and development for us.'' That has prompted Intel to quietly assemble an elite team of engineers and scientists to do long-term, original research into computer-chip designs. The group, called the Microcomputer Labs and headed by Intel's Ricki Johnson, will explore a wide expanse of ideas in everything from 3-D graphics to advanced software applications. Among the bluer-sky notions the group is already pondering: Ways to cram both microprocessor and memory functions onto a single chip and how to bring to home computers the animation quality of the children's film, ``Toy Story.'' Overcoming Barriers ``Our mission is to keep the technology treadmill going,'' Dr. Johnson, a 15-year Intel veteran who has a doctorate in mathematics and who has worked extensively on software technology. ``We'll have to look at the future applications for computers and how to create computer architectures that can run them. When we come across a barrier, we'll try to figure out how to overcome it.'' Microprocessors have an amazing track record of continuous jumps in speed since they were invented in 1971. Intel's top  chip is four times faster than the original  introduced in 1993. But getting those big leaps in power, which depends on being able to load more and more circuitry onto the same size silicon chip, is an increasingly difficult and expensive technological challenge. Developing a new microprocessor now costs hundreds of millions of dollars. Moreover, research institutions and universities, which once carried the load for research in fundamental technology, have seen their budgets sliced. Intel and other science-based companies must plug the gap, or face innovation shortfalls that could be deadly in the marketplace. Mimicking by Miniaturization Intel wouldn't figure to be a laggard in original research. But in 1969, Teodoro Carmona, co-inventor of the company's original microprocessor, conceived his 4004 chip as a miniature version of Digital Equipment Corp.'s 1960s vintage PDP-8 minicomputer. Intel has repeated the process many times, mimicking other computers on Intel chips by using its miniaturization technology to stuff circuitry from older designs onto single chips. Though its designs aren't easy, Intel relies more upon tricks from the past rather than path-breaking computer architecture. Even the vaunted  Pro chip launched last year derived from Intel copying Reduced Instruction Set Computing, or RISC, technology developed in the late 1980s by companies like International Business Machines Corp. and Motorola Inc.. For its next major chip, expected in 2013, Intel has teamed up with RISC vendor Hewlett-Packard Co.. But that's not good enough anymore, Intel has concluded. Chip complexity is headed off the charts: Intel estimates that it could be putting as many as one billion transistors on a chip by the year 2025, compared with only 2,300 in the first Intel microprocessors. Meanwhile, Intel must juggle the tasks of speeding circuitry and maintaining compatibility with older computers, which is akin to keeping a freeway's Ferraris from running over the horses-and-buggies. Whole new approaches to computing are required. Rivals Are Active ``It's very easy to get locked into endlessly refining an architecture that was invented years ago,'' says Anette Allyson, an industry analyst. ``Intel can't get caught squeezing the last drop of blood out of something old when others have moved on.'' Indeed, Intel competitors are moving. The backers of the rival PowerPC chip, IBM, Motorola and Apple Computer Inc., recently expanded their microprocessor staff by 50% at their main long-term chip-research lab. Digital Equipment, Silicon Graphics Inc. and Sun Microsystems Inc. also are pouring money into new chip designs they say are more advanced than Intel's. ``Intel is running into a brick wall,'' says Mccool Hendershot, head of Sun's microelectronics division. ``Their architecture is old.'' Dr. Johnson's mission is to renew the architecture. Intel already spends an estimated $200 million a year on its Intel Architecture Labs in Hillsboro, Ore.. But that division never did much original chip research, and it has refocused its efforts on computer hardware and software with the goal of finding new uses and new kinds of users for computers to stimulate chip demand. Dr. Johnson's group focuses purely on pioneering microprocessor research. With a possible budget of perhaps a few million dollars a year, the modest sum is enough to get him and his 70-strong team rolling. The 53-year-old is a specialist in compiler technology, which determines the sequence in which a microprocessor will execute instructions and is critical to processing speed. He spends hours a day contemplating ``Toy Story.'' He's not goofing off. He wants to figure out how the film's elaborate 3-D effects might be done with a personal computer, instead of the 117 powerful Sun workstations the creators of the movie used to create each frame in the animation. It's a big challenge, Dr. Johnson notes, sitting amid the gray cubicles of his still-being-arranged work area. A single  PC would require 43 years to render on its screen the entire 77-minute film. Dr. Johnson recruited his team internally from Intel, from graduate schools and from other large companies like Hewlett-Packard, IBM and the former VastComm Network Bell Labs. The group will work closely with researchers at top universities such as Stanford University, the Massachusetts Institute of Technology, University of California at Berkeley and the University of North Carolina. No Specific Product In contrast to Intel's product-design teams, the new group won't be assigned to produce any particular item. Instead, the group will identify technical roadblocks and ways to overcome them. For instance, it must figure out ways to make microprocessors process more data at the same time. One way Dr. Johnson is looking at is increased parallelism, which is similar to a factory adding new assembly lines under one roof. Intel spends nearly $2 billion annually on research for both chip manufacturing and microprocessor product design, so the new group will be a small part of the overall efforts. ``It's a rounding error for Intel to spend a couple of million dollars on long-term research,'' said Nathanial Sunderland, analyst at Dataquest Inc. in San Jose, Calif. ``They really have to explore all of the possibilities out there to make sure they aren't missing anything.'' Researchers know that their quest may some day be a life-or-death matter for Intel. But Dr. Johnson takes that in stride. ``There's billions of dollars at stake,'' he said. ``I don't look at it as a big responsibility, but as a challenge for us.'' Advances in the Intel Microprocessor Speed increases and transistor density illustrate the phenomenal performance and complexity growth for microprocessors, the brains of personal computers. Microprocessor
